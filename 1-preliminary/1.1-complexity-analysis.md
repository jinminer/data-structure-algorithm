# 内容提要

* 数据结构和算法本身解决的是“快”和“省”的问题，即如何让代码运行得更快、更省存储空间。

* 执行效率是算法一个非常重要的考量指标。
* 通过时间复杂度和空间复杂度分析来衡量算法代码的执行效率。

# 复杂度分析

## 测试统计法

* 概念
  * 实际工作中会通过统计、监控等手段得到算法执行的时间和占用的内存大小，如压测等。

* 局限性
  1. 测试结果非常依赖测试环境
     * 测试环境中硬件的不同会对测试结果有很大的影响。
  2. 测试结果受数据规模的影响很大
     * 不同的算法在不同量级的数据条件下，效率不同。

## 复杂度分析方法

* 使用时间、空间复杂度分析方法，对算法的执行效率进行粗略的估计，得到较优解。
* 不依赖于具体的环境以及测试数据等外部因素，避免因客观原因得到的错误测试结果而造成生产事故。

### 大 O 复杂度表示法

* 从 CPU 的角度来看，代码的每一行都执行着类似的操作：读数据-运算-写数据。
* 所有代码的执行时间 T(n) 与每行代码的执行次数成正比。

![](https://raw.githubusercontent.com/jinminer/docs/master/data-structure-algorithm/1.1-complexity-analysis/1.0-T(n).png)

> * T(n) ：所有代码执行的总时间
> * n ：数据规模的大小
> * f(n) ：每行代码执行的次数总和。
> * O：代码的执行时间 T(n) 与 f(n) 表达式成正比
>   * 大 O 时间复杂度实际上并不具体表示代码真正的执行时间
>   * 而是表示**代码执行时间随数据规模增长的变化趋势** 
>   * 所以，也叫作**渐进时间复杂度**（asymptotic time complexity），简称**时间复杂度**。

### 时间复杂度分析

时间复杂度分析方法

1. **只关注循环执行次数最多的一段代码**
   * 大 O 复杂度表示方法只是表示一种变化趋势。
   * 通常会忽略掉公式中的常量、低阶、系数，只需要记录一个最大阶的量级。
   * 在分析一个算法、一段代码的时间复杂度的时候，只关注循环执行次数最多的那一段代码就可以
   * 即，核心代码执行次数的 n 的量级，就是整段要分析代码的时间复杂度。

2. **加法法则：总复杂度等于量级最大的那段代码的复杂度**
   * 常量执行时间对时间复杂度的增长趋势无影响
     * 当代码进行有限次循环，是一个常量的执行时间，跟 n 的规模无关，当 n 无限大的时候，就可以忽略。
     * 尽管有限次循环的执行次数较多时，对代码的执行时间会有很大影响，
     * 但是对于时间复杂度的概念而言，它表示的是一个算法执行效率与数据规模增长的变化趋势，所以不管常量的执行时间多大，都可以忽略掉。
     * 因为它本身对增长趋势并没有影响。

3. **乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积** 

## 常见时间复杂度分析

### 复杂度量级

![](https://raw.githubusercontent.com/jinminer/docs/master/data-structure-algorithm/1.1-complexity-analysis/1.1-complexity-magnitude.jpg)

复杂度量级可以分为两类：多项式量级和非多项式量级。其中，非多项式量级只有两个：O(2n) 和 O(n!)。

* 多项式阶：
  * O(1)（常数阶）、O(logn)（对数阶）、O(n)（线性阶）、O(nlogn)（线性对数阶）、O(n^2)（平方阶）、O(n^3)（立方阶）
  * 随着数据规模的增长，算法的执行时间和空间占用，按照多项式的比例增长。
* 非多项式阶：
  * O(2^n)（指数阶）、O(n!)（阶乘阶）
  * 随着数据规模的增长，算法的执行时间和空间占用暴增，这类算法性能极差。
    

### 多项式时间复杂度

几种常见的多项式时间复杂度

1. **O(1) 常量阶**
   * 只要代码的执行时间不随 n 的增大而增长，这样代码的时间复杂度都记作 O(1)。
   * 一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是 Ο(1)。

2. **O(logn)、O(nlogn)**
   * O(logn)
     * 因为 log3n 就等于 log32 * log2n，所以 O(log3n) = O(C * log2n)，其中 C=log32 是一个常量。
     * 在采用大 O 标记复杂度的时候，可以忽略系数，即 O(Cf(n)) = O(f(n))。
     * 所以，O(log2n) 就等于 O(log3n)。
     * 因此，在对数阶时间复杂度的表示方法里，忽略对数的“底”，统一表示为 O(logn)。
   * O(nlogn)
     * 根据乘法法则，如果一段代码的时间复杂度是 O(logn)，循环执行 n 遍，时间复杂度就是 O(nlogn) 。如：归并排序、快速排序的时间复杂度都是 O(nlogn)。

3. **O(m+n)、O(m*n)**
   * 代码的复杂度由**两个数据的规模**来决定
   * 对于一段代码中平级的两个数据规模 m 和 n。如果无法事先评估 m 和 n 谁的量级大，则在表示复杂度的时候，不能简单地利用加法法则，省略掉其中一个。而是表示为两者的和 O(m+n)
   * 两个数据规模的情况，对乘法法则仍然适用



# 空间复杂度分析

* 空间复杂度全称就是**渐进空间复杂度**（asymptotic space complexity），**表示算法的存储空间与数据规模之间的增长关系**。
  * 如：`int[] a = new int[n]` 的空间复杂度是 O(n)。
* 常见的空间复杂度就是 O(1)、O(n)、O(n2 )，像 O(logn)、O(nlogn) 这样的对数阶复杂度平时都用不到。



# 算法执行效率

* 越高阶复杂度的算法，执行效率越低。

  ![](https://raw.githubusercontent.com/jinminer/docs/master/data-structure-algorithm/1.1-complexity-analysis/1.2-complexity-efficiency.jpg)



# 最好、最坏、平均、均摊时间复杂度

* 最好情况时间复杂度（best case time complexity）
* 最坏情况时间复杂度（worst case time complexity）
* 平均情况时间复杂度（average case time complexity）
* 均摊时间复杂度（amortized time complexity）。

## 最好、最坏情况时间复杂度

* 表示代码在不同情况下的不同时间复杂度
  * 最好情况时间复杂度
    * 在最理想的情况下，执行这段代码的时间复杂度
  * 最坏情况时间复杂度
    * 在最糟糕的情况下，执行这段代码的时间复杂度
  * 平均情况时间复杂度。



## 平均情况时间复杂度

* 表示平均情况下的复杂度
* 平均时间复杂度实际上是：加权平均时间复杂度或者期望时间复杂度。
* 只有同一块代码在不同的情况下，时间复杂度有量级的差距，可以使用这三种复杂度表示法来区分。



## 均摊时间复杂度

* 摊还分析法
  * 对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，
  * 而且这些操作之间存在前后连贯的时序关系，这个时候，可以将这一组操作放在一块儿分析，
  * 看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操作上。
  * 而且，在能够应用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复杂度。

























